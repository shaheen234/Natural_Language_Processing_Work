{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        text = file.read().lower() \n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"J. K. Rowling - Harry Potter 4 - The Goblet of Fire.txt\"\n",
    "text = read_file(filename)\n",
    "\n",
    "corpus = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_model(corpus, n):\n",
    "  ngram_model = {}\n",
    "  for i in range(len(corpus) - n + 1):  \n",
    "    gram = tuple(corpus[i:i+n-1])  \n",
    "    if gram not in ngram_model:\n",
    "      ngram_model[gram] = Counter()\n",
    "    next_word = corpus[i+n] if i + n < len(corpus) else None  \n",
    "    if next_word:\n",
    "        ngram_model[gram][next_word] += 1 \n",
    "  for gram, word_counts in ngram_model.items():\n",
    "    total_count = sum(word_counts.values())\n",
    "    ngram_model[gram] = {word: count / total_count for word, count in word_counts.items()}\n",
    "  return ngram_model\n",
    "\n",
    "def generate_word(ngram_model, seed_gram):\n",
    " \n",
    "  if seed_gram not in ngram_model:\n",
    "    \n",
    "    max_prob = 0\n",
    "    most_probable_word = None\n",
    "    for gram, word_probs in ngram_model.items():\n",
    "      for word, prob in word_probs.items():\n",
    "        if prob > max_prob:\n",
    "          max_prob = prob\n",
    "          most_probable_word = word\n",
    "    return most_probable_word\n",
    "  word_probs = ngram_model[seed_gram]\n",
    " \n",
    "  return max(word_probs, key=word_probs.get)\n",
    "\n",
    "def generate_sentence(ngram_model, seed_words, num_words):\n",
    " \n",
    "  sentence = list(seed_words)\n",
    "  for _ in range(num_words):\n",
    "    current_gram = tuple(sentence[-n:]) \n",
    "    next_word = generate_word(ngram_model, current_gram)\n",
    "    sentence.append(next_word)\n",
    "  return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n"
     ]
    }
   ],
   "source": [
    "#for unigram\n",
    "model = create_ngram_model(corpus, 1)  \n",
    "seed_words = [\"he\"] \n",
    "sentence = generate_sentence(model, seed_words, 100) \n",
    "print(\" \".join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he had rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling\n"
     ]
    }
   ],
   "source": [
    "#for bigram\n",
    "model = create_ngram_model(corpus, 2)  \n",
    "seed_words = [\"he\",\"had\"] \n",
    "sentence = generate_sentence(model, seed_words, 100) \n",
    "print(\" \".join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he had awoken rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling rowling\n"
     ]
    }
   ],
   "source": [
    "#for trigram\n",
    "model = create_ngram_model(corpus, 3)  \n",
    "seed_words = [\"he\",\"had\",\"awoken\"] \n",
    "sentence = generate_sentence(model, seed_words, 100) \n",
    "print(\" \".join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he had awoken his\n"
     ]
    }
   ],
   "source": [
    "#interpolation\n",
    "def generate_word_interpolation(ngram_model, current_gram, weights):\n",
    "    probabilities = {}\n",
    "    for gram_size, weight in weights.items():\n",
    "        gram = current_gram[-gram_size:]\n",
    "        if gram in ngram_model:\n",
    "            for word, prob in ngram_model[gram].items():\n",
    "                probabilities[word] = probabilities.get(word, 0) + prob * weight\n",
    "    \n",
    "    if not probabilities:\n",
    "        return None\n",
    "    \n",
    "    return max(probabilities, key=probabilities.get)\n",
    "\n",
    "def generate_sentence_interpolation(ngram_model, seed_words, num_words, weights):\n",
    "    sentence = list(seed_words)\n",
    "    while len(sentence) < num_words:\n",
    "        current_gram = tuple(sentence[-max(weights.keys()):]) \n",
    "        next_word = generate_word_interpolation(ngram_model, current_gram, weights)\n",
    "        if next_word is None:\n",
    "            break\n",
    "        sentence.append(next_word)\n",
    "    return sentence\n",
    "\n",
    "model = create_ngram_model(corpus, 3)  \n",
    "weights = {1: 0.1, 2: 0.4, 3: 0.5} \n",
    "seed_words = [\"he\", \"had\", \"awoken\"]\n",
    "sentence = generate_sentence_interpolation(model, seed_words, 100, weights)\n",
    "print(\" \".join(sentence))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
